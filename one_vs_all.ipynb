{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Yerbol Aussat (SID: 20698564)\n",
    "# CS698, Assignment 3\n",
    "# Logistic Regression (One vs All)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpickle the data\n",
    "def unpickle(file):\n",
    "    import cPickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = cPickle.load(fo)\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import training data\n",
    "batch1_train = unpickle(\"cifar-10-batches-py/data_batch_1\")\n",
    "trn_data = batch1_train['data']\n",
    "trn_labels = np.array(batch1_train['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import testing data\n",
    "batch_test = unpickle(\"cifar-10-batches-py/test_batch\")\n",
    "test_data = batch_test['data']\n",
    "test_labels = np.array(batch_test['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, w):                                                        \n",
    "    z = np.dot(x, w)\n",
    "    return 1.0 / (1.0 + np.exp(-z)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gradient(x, y, w, reg_const, cl):   \n",
    "    # indices of positive and negative labels\n",
    "    y_pos = np.where(y == cl) # locations of y = +1\n",
    "    y_neg = np.where(y != cl) # locations of y = -1\n",
    "    \n",
    "    # number of positive and negative smaples\n",
    "    n_pos = len(y_pos[0])\n",
    "    n_neg = len(y_neg[0])\n",
    "    p = sigmoid(x, w)\n",
    "    # gradient:\n",
    "    g = 1.0/n_pos * np.dot(x[y_pos].T, (p[y_pos] - np.ones((n_pos, 1)) )) + 1.0/n_neg * np.dot(x[y_neg].T, (p[y_neg])) + 2.0 *reg_const * w\n",
    "    return g\n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian(x, y, w, reg_const, cl):  \n",
    "    # indices of positive and negative labels\n",
    "    y_pos = np.where(y == cl) # locations of y = +1\n",
    "    y_neg = np.where(y != cl) # locations of y = -1\n",
    "    \n",
    "    # number of positive and negative smaples\n",
    "    n_pos = len(y_pos[0])\n",
    "    n_neg = len(y_neg[0])\n",
    "    p = sigmoid(x, w)\n",
    "        \n",
    "    # Hessian:\n",
    "    H = 1.0/n_pos * x[y_pos].T.dot(np.diagflat(p[y_pos])).dot(np.diagflat(np.ones((n_pos, 1)) - p[y_pos])).dot(x[y_pos]) + 1.0/n_neg * x[y_neg].T.dot(np.diagflat(p[y_neg])).dot(np.diagflat(np.ones((n_neg, 1)) - p[y_neg])).dot(x[y_neg]) + 2.0 * reg_const * np.identity(len(w))\n",
    "    return H\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def Newton(X_train, y_train, reg_const, cl):\n",
    "    w = np.zeros((3072, 1))\n",
    "    max_pass = 50\n",
    "    \n",
    "    iteration = 0\n",
    "    \n",
    "    while True:\n",
    "        print \"    iteration\", iteration, \": \",\n",
    "        \n",
    "        w_prev = deepcopy(w)\n",
    "        g = gradient(X_train, y_train, w, reg_const, cl)\n",
    "        H = hessian(X_train, y_train, w, reg_const, cl)\n",
    "        w = w_prev - np.linalg.solve(H, g)\n",
    "\n",
    "        print np.linalg.norm(w - w_prev)\n",
    "        iteration += 1 \n",
    "        \n",
    "        if (np.linalg.norm(w - w_prev) < 10**-4) or (iteration >= 50):\n",
    "            return w           \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function calculates percent error of  logistic regression algorithm\n",
    "def percent_error(trn_data, trn_labels, test_data, test_labels, lambdas):\n",
    "    \n",
    "    for i in range(len(lambdas)):   \n",
    "        reg_const = lambdas[i]\n",
    "        w_vectors = []\n",
    "        print \"\\nONE VS ALL: lambda =\", reg_const\n",
    "        \n",
    "        # Training kernel logistic regression algorithm for the value of lambda\n",
    "        print \"Training logistic regression for lambda =\", reg_const\n",
    "        for i in range(10):\n",
    "            print \"\\n  CLASS\", i\n",
    "            w_i = Newton(trn_data, trn_labels, reg_const, i)\n",
    "            w_vectors.append(w_i)\n",
    "        \n",
    "        # Testing kernel logistic regression algorithm for lambda = 1\n",
    "        print \"Testing logistic regression for lambda =\", reg_const\n",
    "        incorrect = 0\n",
    "        for sample_i in range(len(test_labels)):\n",
    "            x = test_data[sample_i]\n",
    "            p = []\n",
    "            for i in range(10):\n",
    "                w0 = w_vectors[i]\n",
    "                p0 = np.dot(w0.T, x) #p0 = sigmoid(x, w0)\n",
    "                p.append(p0)\n",
    "            prediction = np.argmax(p)\n",
    "            if prediction != test_labels[sample_i]:\n",
    "                incorrect+=1\n",
    "                \n",
    "        print \"\\nOne vs All: lambda =\", reg_const, \":\"\n",
    "        print \"  Num Incorrectly Classified:\", incorrect\n",
    "        print \"  Percent Error:\", 1.0*incorrect / len(test_labels)\n",
    "        print \"\\n\", '*'*40, '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ONE VS ALL: lambda = 0.1\n",
      "Training logistic regression for lambda = 0.1\n",
      "\n",
      "  CLASS 0\n",
      "    iteration 0 :  0.439136438427\n",
      "    iteration 1 :  0.223073027283\n",
      "    iteration 2 :  0.186901394459\n",
      "    iteration 3 :  0.124386092956\n",
      "    iteration 4 :  0.048775499788\n",
      "    iteration 5 :  0.00675425913587\n",
      "    iteration 6 :  0.000156232995119\n",
      "    iteration 7 :  1.47933395375e-07\n",
      "\n",
      "  CLASS 1\n",
      "    iteration 0 :  0.427668293617\n",
      "    iteration 1 :  0.213156088216\n",
      "    iteration 2 :  0.192667945279\n",
      "    iteration 3 :  0.16610295977\n",
      "    iteration 4 :  0.124605522531\n",
      "    iteration 5 :  0.0584718366399\n",
      "    iteration 6 :  0.0121113528642\n",
      "    iteration 7 :  0.000590342173505\n",
      "    iteration 8 :  2.29669420029e-06\n",
      "\n",
      "  CLASS 2\n",
      "    iteration 0 :  0.50929105672\n",
      "    iteration 1 :  0.239085348763\n",
      "    iteration 2 :  0.174251896775\n",
      "    iteration 3 :  0.0857165910648\n",
      "    iteration 4 :  0.0202821672256\n",
      "    iteration 5 :  0.00114047164789\n",
      "    iteration 6 :  6.8010504296e-06\n",
      "\n",
      "  CLASS 3\n",
      "    iteration 0 :  0.496684421841\n",
      "    iteration 1 :  0.232761863231\n",
      "    iteration 2 :  0.17160563961\n",
      "    iteration 3 :  0.0937616143537\n",
      "    iteration 4 :  0.0258013564037\n",
      "    iteration 5 :  0.00183567421584\n",
      "    iteration 6 :  1.90188209893e-05\n",
      "\n",
      "  CLASS 4\n",
      "    iteration 0 :  0.483806522983\n",
      "    iteration 1 :  0.230519865933\n",
      "    iteration 2 :  0.181540558089\n",
      "    iteration 3 :  0.103978899387\n",
      "    iteration 4 :  0.0323822821021\n",
      "    iteration 5 :  0.00321852219508\n",
      "    iteration 6 :  3.91450359244e-05\n",
      "\n",
      "  CLASS 5\n",
      "    iteration 0 :  0.489449625851\n",
      "    iteration 1 :  0.231153983554\n",
      "    iteration 2 :  0.194713375143\n",
      "    iteration 3 :  0.132735748877\n",
      "    iteration 4 :  0.0507843964447\n",
      "    iteration 5 :  0.00685494922573\n",
      "    iteration 6 :  0.000156705603542\n",
      "    iteration 7 :  1.73427247957e-07\n",
      "\n",
      "  CLASS 6\n",
      "    iteration 0 :  0.448885252445\n",
      "    iteration 1 :  0.212628620457\n",
      "    iteration 2 :  0.190928048778\n",
      "    iteration 3 :  0.166315204528\n",
      "    iteration 4 :  0.103242207131\n",
      "    iteration 5 :  0.0347838840126\n",
      "    iteration 6 :  0.00397089338018\n",
      "    iteration 7 :  6.77646254631e-05\n",
      "\n",
      "  CLASS 7\n",
      "    iteration 0 :  0.458769791581\n",
      "    iteration 1 :  0.225110488406\n",
      "    iteration 2 :  0.198807413614\n",
      "    iteration 3 :  0.149261400583\n",
      "    iteration 4 :  0.081271740349\n",
      "    iteration 5 :  0.0194176153657\n",
      "    iteration 6 :  0.00119674511405\n",
      "    iteration 7 :  1.02471587473e-05\n",
      "\n",
      "  CLASS 8\n",
      "    iteration 0 :  0.423504510576\n",
      "    iteration 1 :  0.210488627239\n",
      "    iteration 2 :  0.183739242386\n",
      "    iteration 3 :  0.134081897589\n",
      "    iteration 4 :  0.0631727137323\n",
      "    iteration 5 :  0.0119069781024\n",
      "    iteration 6 :  0.000449190476336\n",
      "    iteration 7 :  8.44276675917e-07\n",
      "\n",
      "  CLASS 9\n",
      "    iteration 0 :  0.418294562024\n",
      "    iteration 1 :  0.211906988328\n",
      "    iteration 2 :  0.194202825246\n",
      "    iteration 3 :  0.162566122145\n",
      "    iteration 4 :  0.119805534951\n",
      "    iteration 5 :  0.0539907063041\n",
      "    iteration 6 :  0.00899862619993\n",
      "    iteration 7 :  0.00029401349815\n",
      "    iteration 8 :  4.97135149937e-07\n",
      "Testing logistic regression for lambda = 0.1\n",
      "\n",
      "One vs All: lambda = 0.1 :\n",
      "  Num Incorrectly Classified: 7405\n",
      "  Percent Error: 0.7405\n",
      "\n",
      "**************************************** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finding percent error for lambdas = 0.1, 1, 10\n",
    "percent_error(trn_data, trn_labels, test_data, test_labels, [0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ONE VS ALL: lambda = 1\n",
      "Training logistic regression for lambda = 1\n",
      "\n",
      "  CLASS 0\n",
      "    iteration 0 :  0.165769640632\n",
      "    iteration 1 :  0.072899244647\n",
      "    iteration 2 :  0.0494241717706\n",
      "    iteration 3 :  0.0198616363915\n",
      "    iteration 4 :  0.0027842101685\n",
      "    iteration 5 :  0.00010835387399\n",
      "    iteration 6 :  6.5880301158e-07\n",
      "\n",
      "  CLASS 1\n",
      "    iteration 0 :  0.170312590433\n",
      "    iteration 1 :  0.0748954392698\n",
      "    iteration 2 :  0.058050682675\n",
      "    iteration 3 :  0.0364628284309\n",
      "    iteration 4 :  0.0119011783184\n",
      "    iteration 5 :  0.00115984011274\n",
      "    iteration 6 :  1.3330002746e-05\n",
      "\n",
      "  CLASS 2\n",
      "    iteration 0 :  0.189793499129\n",
      "    iteration 1 :  0.0713307418017\n",
      "    iteration 2 :  0.0352022064359\n",
      "    iteration 3 :  0.00885834971374\n",
      "    iteration 4 :  0.000623690328779\n",
      "    iteration 5 :  6.07445883654e-06\n",
      "\n",
      "  CLASS 3\n",
      "    iteration 0 :  0.188441856921\n",
      "    iteration 1 :  0.0697574425103\n",
      "    iteration 2 :  0.0380758620547\n",
      "    iteration 3 :  0.0106710218549\n",
      "    iteration 4 :  0.000785266686965\n",
      "    iteration 5 :  6.20418514809e-06\n",
      "\n",
      "  CLASS 4\n",
      "    iteration 0 :  0.187759674615\n",
      "    iteration 1 :  0.071432712641\n",
      "    iteration 2 :  0.0398555477767\n",
      "    iteration 3 :  0.0127792751389\n",
      "    iteration 4 :  0.00119641951685\n",
      "    iteration 5 :  1.26685940974e-05\n",
      "\n",
      "  CLASS 5\n",
      "    iteration 0 :  0.184915411554\n",
      "    iteration 1 :  0.0768304227351\n",
      "    iteration 2 :  0.0455666124376\n",
      "    iteration 3 :  0.0160633739502\n",
      "    iteration 4 :  0.00177450175822\n",
      "    iteration 5 :  2.33963769858e-05\n",
      "\n",
      "  CLASS 6\n",
      "    iteration 0 :  0.171037491527\n",
      "    iteration 1 :  0.0733592369733\n",
      "    iteration 2 :  0.0543507390916\n",
      "    iteration 3 :  0.0304772140751\n",
      "    iteration 4 :  0.00784923033145\n",
      "    iteration 5 :  0.000497358241465\n",
      "    iteration 6 :  3.17764402692e-06\n",
      "\n",
      "  CLASS 7\n",
      "    iteration 0 :  0.174833232169\n",
      "    iteration 1 :  0.0739667209449\n",
      "    iteration 2 :  0.0518596944293\n",
      "    iteration 3 :  0.0246216839963\n",
      "    iteration 4 :  0.00462074966419\n",
      "    iteration 5 :  0.000163041434977\n",
      "    iteration 6 :  2.53056210634e-07\n",
      "\n",
      "  CLASS 8\n",
      "    iteration 0 :  0.155968591958\n",
      "    iteration 1 :  0.0696301350556\n",
      "    iteration 2 :  0.0484070786725\n",
      "    iteration 3 :  0.0223591376043\n",
      "    iteration 4 :  0.00405043774473\n",
      "    iteration 5 :  0.000136064425559\n",
      "    iteration 6 :  2.08522251782e-07\n",
      "\n",
      "  CLASS 9\n",
      "    iteration 0 :  0.16462155813\n",
      "    iteration 1 :  0.0730912733978\n",
      "    iteration 2 :  0.0558302812486\n",
      "    iteration 3 :  0.034020572096\n",
      "    iteration 4 :  0.0110051258923\n",
      "    iteration 5 :  0.00100096216754\n",
      "    iteration 6 :  1.06248023073e-05\n",
      "Testing logistic regression for lambda = 1\n",
      "\n",
      "One vs All: lambda = 1 :\n",
      "  Num Incorrectly Classified: 7103\n",
      "  Percent Error: 0.7103\n",
      "\n",
      "**************************************** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "percent_error(trn_data, trn_labels, test_data, test_labels, [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ONE VS ALL: lambda = 10\n",
      "Training logistic regression for lambda = 10\n",
      "\n",
      "  CLASS 0\n",
      "    iteration 0 :  0.0586425421105\n",
      "    iteration 1 :  0.0209560505942\n",
      "    iteration 2 :  0.00932956574315\n",
      "    iteration 3 :  0.00172173630652\n",
      "    iteration 4 :  8.62099406288e-05\n",
      "\n",
      "  CLASS 1\n",
      "    iteration 0 :  0.0650190678603\n",
      "    iteration 1 :  0.0242587131961\n",
      "    iteration 2 :  0.0139036903026\n",
      "    iteration 3 :  0.00430091789549\n",
      "    iteration 4 :  0.000371497396157\n",
      "    iteration 5 :  3.06095024211e-06\n",
      "\n",
      "  CLASS 2\n",
      "    iteration 0 :  0.0650827602944\n",
      "    iteration 1 :  0.018788991749\n",
      "    iteration 2 :  0.00579337462738\n",
      "    iteration 3 :  0.000631810277774\n",
      "    iteration 4 :  8.86797598791e-06\n",
      "\n",
      "  CLASS 3\n",
      "    iteration 0 :  0.0651187883684\n",
      "    iteration 1 :  0.0182029610259\n",
      "    iteration 2 :  0.00693769634869\n",
      "    iteration 3 :  0.000707636597148\n",
      "    iteration 4 :  1.01517569892e-05\n",
      "\n",
      "  CLASS 4\n",
      "    iteration 0 :  0.0652439189175\n",
      "    iteration 1 :  0.0190953742549\n",
      "    iteration 2 :  0.00706770812845\n",
      "    iteration 3 :  0.000855338389203\n",
      "    iteration 4 :  1.32375329292e-05\n",
      "\n",
      "  CLASS 5\n",
      "    iteration 0 :  0.0660785165862\n",
      "    iteration 1 :  0.020163567795\n",
      "    iteration 2 :  0.007526292918\n",
      "    iteration 3 :  0.00104287690552\n",
      "    iteration 4 :  1.98327925235e-05\n",
      "\n",
      "  CLASS 6\n",
      "    iteration 0 :  0.0623720372053\n",
      "    iteration 1 :  0.0222301636342\n",
      "    iteration 2 :  0.0120769730875\n",
      "    iteration 3 :  0.00334233270774\n",
      "    iteration 4 :  0.000238328855429\n",
      "    iteration 5 :  1.30181732502e-06\n",
      "\n",
      "  CLASS 7\n",
      "    iteration 0 :  0.0615921598264\n",
      "    iteration 1 :  0.0222979787769\n",
      "    iteration 2 :  0.0110483083351\n",
      "    iteration 3 :  0.00240470903865\n",
      "    iteration 4 :  0.000109161384556\n",
      "    iteration 5 :  2.66009157603e-07\n",
      "\n",
      "  CLASS 8\n",
      "    iteration 0 :  0.054719700813\n",
      "    iteration 1 :  0.020123328989\n",
      "    iteration 2 :  0.0106332856237\n",
      "    iteration 3 :  0.00254071767415\n",
      "    iteration 4 :  0.000140299769951\n",
      "    iteration 5 :  5.40794947754e-07\n",
      "\n",
      "  CLASS 9\n",
      "    iteration 0 :  0.0606655332835\n",
      "    iteration 1 :  0.0228689259692\n",
      "    iteration 2 :  0.0131524167844\n",
      "    iteration 3 :  0.00388362389036\n",
      "    iteration 4 :  0.000317742741643\n",
      "    iteration 5 :  2.25392478921e-06\n",
      "Testing logistic regression for lambda = 10\n",
      "\n",
      "One vs All: lambda = 10 :\n",
      "  Num Incorrectly Classified: 6815\n",
      "  Percent Error: 0.6815\n",
      "\n",
      "**************************************** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "percent_error(trn_data, trn_labels, test_data, test_labels, [10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
